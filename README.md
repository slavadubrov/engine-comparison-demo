# The Engine Wars â€” Live Demo

**Benchmark Pandas vs. Polars vs. DataFusion vs. Daft on real-world datasets.**

No synthetic data. No toy examples. Real NYC taxi trips and real food photos.

---

## Quick Start

```bash
# 1. Install uv (if you don't have it)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. Sync dependencies
uv sync

# 3. Pre-download datasets (optional â€” benchmarks auto-download on first run)
uv run python -m engine_comparison.data.loader

# 4. Run the tabular benchmark (~2.9M NYC taxi trips)
uv run python -m engine_comparison.benchmarks.tabular

# 5. Run the multimodal benchmark (5000 real food photos)
uv run python -m engine_comparison.benchmarks.multimodal
```

First run downloads ~50 MB of data. Subsequent runs use the cache in `.data/`.

---

## Datasets

### Tabular: NYC Yellow Taxi Trip Records

| Attribute | Value |
|---|---|
| Source | [NYC Taxi & Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) |
| Format | Apache Parquet |
| Default | January 2024 (~2.9M rows Ã— 19 columns, ~45 MB) |
| Join table | Taxi Zone Lookup (265 zones with borough names) |

Real taxi trip records: pickup/dropoff times, locations, distances, fares,
tips, payment types. The join table maps numeric location IDs to human-readable
borough and zone names (e.g., "Manhattan â€” Upper East Side North").

### Multimodal: Food-101 (ETH Zurich)

| Attribute | Value |
|---|---|
| Source | [ETH Zurich via Hugging Face](https://huggingface.co/datasets/ethz/food101) |
| Format | JPEG images |
| Default | 5000 images (configurable) |
| Content | Real food photos â€” pizza, sushi, steak, etc. |

Real photographs of food in 101 categories. Variable sizes and aspect ratios,
exactly like production ML preprocessing pipelines encounter.

---

## What's Benchmarked

### `bench_tabular.py` â€” Tabular Operations

| Operation | What it tests | Real-world analogy |
|---|---|---|
| Read Parquet | Full scan of ~45 MB file | Loading a dataset for analysis |
| Filter | `distance > 5mi AND fare > $30` | Finding high-value trips |
| GroupBy + Agg | Revenue by payment type | Payment analytics dashboard |
| Join | Trip data âŸ• Zone lookup | Enriching with borough names |
| ETL Pipeline | Filter â†’ Join â†’ Aggregate â†’ Sort | Building a revenue report |

Engines: **Pandas** Â· **Polars** Â· **DataFusion** Â· **Daft**

### `bench_multimodal.py` â€” Image Processing

| Operation | What it tests | Real-world analogy |
|---|---|---|
| Load Images | Read + decode JPEGs | ML data pipeline ingestion |
| Resize 224Ã—224 | Resize to model input size | Preprocessing for ResNet/ViT |
| Total Pipeline | Load â†’ Decode â†’ Resize | End-to-end ML preprocessing |

Engines: **Pandas + Pillow** (sequential) vs. **Daft** (parallel Rust)

> Polars and DataFusion are excluded from the multimodal benchmark because
> they lack native image operations â€” image work would still go through
> sequential Python.

---

## CLI Options

```bash
# Tabular: change data month
uv run python -m engine_comparison.benchmarks.tabular --year 2023 --month 6

# Tabular: more timing precision
uv run python -m engine_comparison.benchmarks.tabular --runs 5

# Multimodal: more images = larger speedup (more parallelism)
uv run python -m engine_comparison.benchmarks.multimodal --images 1000

# Multimodal: quick smoke test
uv run python -m engine_comparison.benchmarks.multimodal --images 100
```

---

## Docker Compose (Distributed Stack)

Run the distributed pipelines locally using Docker Compose with GPU support.

### Prerequisites

- **Docker** 20.10+ with Compose v2
- **NVIDIA Docker** (for GPU support) â€” [Installation Guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- **~16 GB RAM** recommended for full stack

### Quick Start

```bash
# 1. Build all images
docker compose build

# 2. Start the distributed stack
docker compose up -d

# 3. Check services
docker compose ps
```

### Web UIs

| Service | URL | Description |
|---------|-----|-------------|
| MinIO Console | http://localhost:9001 | S3 browser (login: `minioadmin` / `minioadmin`) |
| Spark UI | http://localhost:8080 | Spark master dashboard |
| Ray Dashboard | http://localhost:8265 | Ray cluster status |

### Running Pipelines

```bash
# Spark ETL (NYC Taxi)
./scripts/docker-run-spark.sh --orders s3a://lake/taxi/*.parquet --output s3a://warehouse/report/

# Ray inference (GPU image classification)
./scripts/docker-run-ray.sh --input s3://bucket/images/ --output s3://bucket/predictions/

# Daft pipeline (document embedding)
./scripts/docker-run-daft.sh --input s3://lake/pdfs.parquet --output s3://output/embeddings/
```

### Uploading Test Data

```bash
# Upload local files to MinIO
./scripts/upload-data.sh .data/food101 bucket/images/
```

### Stopping

```bash
docker compose down          # Stop services
docker compose down -v       # Stop and remove volumes (clears MinIO data)
```

---

## Distributed Scripts (Cluster Required)

The `src/engine_comparison/distributed/` directory contains reference
implementations for cluster-scale processing:

| Module | Engine | Workload |
|---|---|---|
| `ray_inference` | Ray Data | GPU batch image classification |
| `daft_pipeline` | Daft Flotilla | Distributed document embedding |
| `spark_etl` | PySpark | Petabyte-scale tabular ETL |

Install extras: `uv sync --extra distributed`

These require actual cluster infrastructure (Ray, Spark, or Daft Cloud).

---

## Expected Output

### Tabular benchmark

```
âš¡ Engine Wars â€” NYC Taxi Benchmark Results
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Operation        â”ƒ           Pandas â”ƒ           Polars â”ƒ       DataFusion â”ƒ             Daft â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Read Parquet     â”‚           0.062s â”‚      0.062s 1.0Ã— â”‚      0.073s 0.8Ã— â”‚      0.067s 0.9Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Filter           â”‚           0.016s â”‚      0.024s 0.7Ã— â”‚      0.059s 0.3Ã— â”‚      0.083s 0.2Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GroupBy + Agg    â”‚           0.068s â”‚      0.019s 3.7Ã— â”‚      0.023s 3.0Ã— â”‚      0.023s 3.0Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Join             â”‚           0.121s â”‚      0.098s 1.2Ã— â”‚      0.164s 0.7Ã— â”‚      0.141s 0.9Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ETL Pipeline     â”‚           0.153s â”‚      0.039s 4.0Ã— â”‚      0.038s 4.0Ã— â”‚      0.070s 2.2Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total            â”‚            0.42s â”‚       0.24s 1.7Ã— â”‚       0.36s 1.2Ã— â”‚       0.38s 1.1Ã— â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*(Results from a 10-core Mac â€” your numbers will vary by hardware.)*

![Tabular Benchmark Results](benchmarks/benchmark_results.png)

### Multimodal benchmark

```
ğŸ–¼  Engine Wars â€” Food-101 Multimodal Benchmark
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Operation          â”ƒ    Pandas + Pillow â”ƒ        Daft (Rust) â”ƒ    Speedup â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Load Images        â”‚             3.840s â”‚             3.863s â”‚       1.0Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Resize 224Ã—224     â”‚             5.775s â”‚             3.321s â”‚       1.7Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total Pipeline     â”‚            10.980s â”‚             3.832s â”‚       2.9Ã— â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

![Multimodal Benchmark Results](benchmarks/multimodal_results.png)

Saves `multimodal_results.png` â€” a comparison chart.

---

## Requirements

- **Python** 3.10 â€“ 3.12
- **uv** (recommended) or pip
- **~2 GB free RAM** for the tabular benchmark
- **Internet** on first run (downloads ~50 MB total, then cached)
- Works on **macOS**, **Linux**, and **Windows**

---

## Project Structure

```
engine-comparison-demo/
â”œâ”€â”€ pyproject.toml                      # uv/pip project config
â”œâ”€â”€ Dockerfile                          # GPU-enabled Python container
â”œâ”€â”€ docker-compose.yml                  # Spark, Ray, MinIO stack
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ docker-run-spark.sh             # Run Spark ETL
â”‚   â”œâ”€â”€ docker-run-ray.sh               # Run Ray inference
â”‚   â”œâ”€â”€ docker-run-daft.sh              # Run Daft pipeline
â”‚   â””â”€â”€ upload-data.sh                  # Upload to MinIO
â”œâ”€â”€ src/engine_comparison/              # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py                    # Centralized configuration
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ loader.py                   # Downloads + caches datasets
â”‚   â”œâ”€â”€ benchmarks/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tabular.py                  # NYC Taxi benchmark
â”‚   â”‚   â””â”€â”€ multimodal.py               # Food-101 benchmark
â”‚   â””â”€â”€ distributed/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ray_inference.py            # Ray Data GPU inference
â”‚       â”œâ”€â”€ daft_pipeline.py            # Daft distributed embedding
â”‚       â””â”€â”€ spark_etl.py                # PySpark ETL
â””â”€â”€ .data/                              # Auto-created cache (gitignored)
    â”œâ”€â”€ nyc_taxi/
    â”‚   â”œâ”€â”€ yellow_tripdata_2024-01.parquet
    â”‚   â””â”€â”€ taxi_zone_lookup.csv
    â””â”€â”€ food101/
        â””â”€â”€ food_00000.jpg ... food_04999.jpg
```
