{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Ray Data on Docker Compose\n",
    "Streaming GPU inference with Ray Data — built for GPU saturation and heterogeneous scheduling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Start the Ray stack and launch Jupyter:\n",
    "\n",
    "```bash\n",
    "# 1. Build images\n",
    "docker compose build\n",
    "\n",
    "# 2. Start MinIO + Ray + App\n",
    "docker compose up -d minio minio-setup ray-head app\n",
    "\n",
    "# 3. Upload sample data\n",
    "./scripts/upload-data.sh\n",
    "\n",
    "# 4. Launch Jupyter Lab\n",
    "docker compose exec app jupyter lab --ip 0.0.0.0 --port 8888 --allow-root --no-browser --notebook-dir=/app/notebook\n",
    "```\n",
    "\n",
    "Then open http://localhost:8888 in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## What is Ray Data?\n",
    "\n",
    "Ray Data is a streaming data framework designed for **GPU-heavy ML workloads**. Key concepts:\n",
    "\n",
    "- **Datasets** — distributed, streaming collections of Arrow-backed rows\n",
    "- **map_batches** — the core operation: apply a function to batches of data\n",
    "- **ActorPoolStrategy** — persistent GPU workers with model loaded once per actor\n",
    "- **Streaming execution** — bounded memory, backpressure-aware\n",
    "- **Heterogeneous scheduling** — CPU preprocessing → GPU inference seamlessly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "```\n",
    "Client (app) → Ray Head (GPU execution) → MinIO (S3 storage)\n",
    "```\n",
    "\n",
    "The app connects to the Ray cluster as a client. Ray schedules tasks on the head node (or workers). Data reads/writes go through MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(\"ray://ray-head:10001\")\n",
    "\n",
    "resources = ray.cluster_resources()\n",
    "print(f\"Cluster resources:\")\n",
    "for k, v in sorted(resources.items()):\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## Read Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ray.data.read_parquet(\"s3://lake/taxi/\")\n",
    "\n",
    "print(f\"Schema: {ds.schema()}\")\n",
    "print(f\"Count: {ds.count():,}\")\n",
    "ds.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Basic Transformations\n",
    "\n",
    "`map_batches` applies a function to each batch. For CPU transforms, no special config needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_tip_pct(batch):\n",
    "    \"\"\"Add tip percentage column.\"\"\"\n",
    "    fare = np.array(batch[\"fare_amount\"])\n",
    "    tip = np.array(batch[\"tip_amount\"])\n",
    "    batch[\"tip_pct\"] = np.where(fare > 0, tip / fare * 100, 0.0)\n",
    "    return batch\n",
    "\n",
    "\n",
    "transformed = ds.map_batches(add_tip_pct)\n",
    "transformed.select_columns([\"fare_amount\", \"tip_amount\", \"tip_pct\"]).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ray.data.read_images(\"s3://bucket/images/\")\n",
    "print(f\"Image count: {images.count()}\")\n",
    "images.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## GPU Inference with ActorPoolStrategy\n",
    "\n",
    "The `ImageClassifier` loads ResNet-50 **once per actor** and reuses it across batches.\n",
    "This avoids the cost of loading a model for every batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import ResNet50_Weights, resnet50\n",
    "\n",
    "\n",
    "class ImageClassifier:\n",
    "    \"\"\"Stateful GPU actor — model loaded ONCE, reused for all batches.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.weights = ResNet50_Weights.DEFAULT\n",
    "        self.model = resnet50(weights=self.weights).to(self.device).eval()\n",
    "        self.preprocess = self.weights.transforms()\n",
    "        self.categories = self.weights.meta[\"categories\"]\n",
    "        print(f\"[ImageClassifier] ResNet-50 loaded on {self.device}\")\n",
    "\n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        tensors = torch.stack(\n",
    "            [\n",
    "                self.preprocess(torch.from_numpy(img).permute(2, 0, 1))\n",
    "                for img in batch[\"image\"]\n",
    "            ]\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(tensors)\n",
    "\n",
    "        top_idx = logits.argmax(dim=1).cpu().numpy()\n",
    "        return {\n",
    "            \"prediction\": [self.categories[i] for i in top_idx],\n",
    "            \"confidence\": logits.softmax(dim=1).max(dim=1).values.cpu().numpy(),\n",
    "        }\n",
    "\n",
    "\n",
    "predictions = images.map_batches(\n",
    "    ImageClassifier,\n",
    "    compute=ray.data.ActorPoolStrategy(size=1),\n",
    "    num_gpus=1,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "## Inspect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(10)\n",
    "\n",
    "# Class distribution\n",
    "pdf = predictions.to_pandas()\n",
    "print(\"\\nTop-10 predicted classes:\")\n",
    "print(pdf[\"prediction\"].value_counts().head(10).to_string())\n",
    "\n",
    "print(\n",
    "    f\"\\nConfidence — avg: {pdf['confidence'].mean():.4f}, \"\n",
    "    f\"min: {pdf['confidence'].min():.4f}, \"\n",
    "    f\"max: {pdf['confidence'].max():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "## Write Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write_parquet(\"s3://bucket/notebook_predictions/\")\n",
    "print(\"Written to s3://bucket/notebook_predictions/\")\n",
    "\n",
    "# Read back to verify\n",
    "saved = ray.data.read_parquet(\"s3://bucket/notebook_predictions/\")\n",
    "print(f\"Read back {saved.count():,} rows\")\n",
    "saved.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "print(\"Ray disconnected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}